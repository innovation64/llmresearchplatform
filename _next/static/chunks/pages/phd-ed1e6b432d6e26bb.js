(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[717],{2149:function(e,s,a){(window.__NEXT_P=window.__NEXT_P||[]).push(["/phd",function(){return a(1395)}])},1395:function(e,s,a){"use strict";a.r(s),a.d(s,{default:function(){return t}});var r=a(5893),i=a(1664),n=a.n(i),l=a(6250);function t(){return(0,r.jsxs)("div",{children:[(0,r.jsxs)("section",{className:"relative bg-gradient-to-br from-blue-700 via-blue-800 to-indigo-900 text-white py-20 overflow-hidden",children:[(0,r.jsxs)("div",{className:"absolute inset-0 opacity-10",children:[(0,r.jsx)("div",{className:"absolute top-0 right-0 w-96 h-96 bg-blue-300 rounded-full blur-3xl"}),(0,r.jsx)("div",{className:"absolute bottom-0 left-0 w-72 h-72 bg-indigo-300 rounded-full blur-3xl"})]}),(0,r.jsx)("div",{className:"container mx-auto px-4 relative z-10",children:(0,r.jsxs)("div",{className:"max-w-3xl mx-auto text-center",children:[(0,r.jsx)("div",{className:"inline-block px-4 py-1.5 bg-white/15 backdrop-blur-sm rounded-full text-sm font-medium mb-6 border border-white/20",children:"Actively Seeking PhD Positions"}),(0,r.jsx)("h1",{className:"text-4xl md:text-5xl font-bold mb-6",children:"PhD Position in LLM Research"}),(0,r.jsx)("p",{className:"text-xl md:text-2xl mb-4 opacity-90",children:"Looking for opportunities to advance research in brain-inspired memory, multi-agent systems, and domain-specific LLMs"})]})})]}),(0,r.jsx)("section",{className:"section bg-white",children:(0,r.jsx)("div",{className:"container",children:(0,r.jsxs)("div",{className:"max-w-4xl mx-auto",children:[(0,r.jsxs)("div",{className:"bg-gradient-to-r from-blue-50 to-indigo-50 rounded-lg p-6 mb-10 border border-blue-100",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Overview"}),(0,r.jsx)("p",{className:"text-lg mb-6",children:"I am actively seeking PhD positions to continue my research in large language models, brain-inspired memory architectures, multi-agent systems, and domain-specific LLMs. With publications at EMNLP and KDD, experience at GIIST, HKMU, Tsinghua NLP Lab, and Zhipu AI, I bring a strong research track record and hands-on experience across the full LLM stack."}),(0,r.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6",children:[(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.HR2,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Academic Background"}),(0,r.jsx)("p",{className:"text-gray-700",children:"B.Sc. Information Management & Information Systems, Beijing University of Chinese Medicine (2018–2022)"})]})]}),(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.i63,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Current Position"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Research Assistant, Guangdong Institute of Intelligence Science and Technology (GIIST), Aug 2025–Present"})]})]}),(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.hbr,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Research Experience"}),(0,r.jsx)("p",{className:"text-gray-700",children:"GIIST (2025–Present), HKMU (2023–2025), THU NLP (2023), Zhipu AI (2022–2023)"})]})]}),(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.xUG,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Research Focus"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Brain-inspired memory, multi-agent systems, RAG, reasoning, domain-specific LLMs"})]})]}),(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.WY8,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Community Involvement"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Hugging Face Chinese Community Lead, AITIME Volunteer, Journal Reviewer (NLP Journal, IEEE IoT)"})]})]}),(0,r.jsxs)("div",{className:"flex",children:[(0,r.jsx)("div",{className:"flex-shrink-0 mr-4 text-primary",children:(0,r.jsx)(l.nae,{size:24})}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-1",children:"Technical Skills"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Python, PyTorch, React, Docker, Smolagents, distributed training (H100 GPUs)"})]})]})]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-6",children:"Research Timeline"}),(0,r.jsxs)("div",{className:"space-y-0 mb-10 border-l-2 border-blue-200 ml-4",children:[(0,r.jsxs)("div",{className:"relative pl-8 pb-8",children:[(0,r.jsx)("div",{className:"absolute left-0 top-1 w-3 h-3 bg-blue-600 rounded-full -translate-x-[7px]"}),(0,r.jsxs)("div",{className:"flex items-center gap-2 mb-1",children:[(0,r.jsx)("span",{className:"text-sm font-semibold text-blue-600",children:"Aug 2025 – Present"}),(0,r.jsx)("span",{className:"tag bg-green-100 text-green-800 text-xs",children:"Current"})]}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Research Assistant — GIIST, Zhuhai"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm mt-1",children:"Brain-inspired memory architectures, Pain LLM with 20+ H100 GPUs, pain mouse behavioral benchmarks, China Brain Project, FDCT grant proposals"})]}),(0,r.jsxs)("div",{className:"relative pl-8 pb-8",children:[(0,r.jsx)("div",{className:"absolute left-0 top-1 w-3 h-3 bg-blue-400 rounded-full -translate-x-[7px]"}),(0,r.jsx)("span",{className:"text-sm font-semibold text-blue-600",children:"Aug 2023 – Aug 2025"}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Research Assistant — HKMU, Hong Kong"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm mt-1",children:"CondAmbigQA benchmark (EMNLP 2025), condition reasoning improving LLM accuracy by 18.9%, GRF/NSFC grant proposals, journal reviewer"})]}),(0,r.jsxs)("div",{className:"relative pl-8 pb-8",children:[(0,r.jsx)("div",{className:"absolute left-0 top-1 w-3 h-3 bg-blue-300 rounded-full -translate-x-[7px]"}),(0,r.jsx)("span",{className:"text-sm font-semibold text-blue-600",children:"Feb 2023 – Aug 2023"}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Research Collaborator — Tsinghua NLP Lab"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm mt-1",children:"XAgent framework for multi-agent collaboration, ReproAgent RAG module"})]}),(0,r.jsxs)("div",{className:"relative pl-8 pb-8",children:[(0,r.jsx)("div",{className:"absolute left-0 top-1 w-3 h-3 bg-blue-200 rounded-full -translate-x-[7px]"}),(0,r.jsx)("span",{className:"text-sm font-semibold text-blue-600",children:"Aug 2022 – Feb 2023"}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Algorithm Engineer (Intern) — Zhipu AI (THU KEG)"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm mt-1",children:"CodeGeeX code generation model (KDD 2023), GLM-based poetry generation, prompt engineering"})]}),(0,r.jsxs)("div",{className:"relative pl-8",children:[(0,r.jsx)("div",{className:"absolute left-0 top-1 w-3 h-3 bg-blue-100 rounded-full -translate-x-[7px] border border-blue-300"}),(0,r.jsx)("span",{className:"text-sm font-semibold text-blue-600",children:"Jul 2021 – Jul 2022"}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Founder Member — Shenzhen InnoX Academy"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm mt-1",children:"Emotional companion robots, SLAM-based autonomous navigation, smart wheelchairs, embodied AI"})]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-6",children:"Research Interests for PhD"}),(0,r.jsxs)("div",{className:"space-y-6 mb-10",children:[(0,r.jsxs)("div",{className:"border-l-4 border-purple-600 pl-4",children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Brain-Inspired Memory Architectures for LLMs"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Building on the BMAM framework to develop neuroscience-principled memory systems that enable agents with human-like consolidation, forgetting, and retrieval capabilities."})]}),(0,r.jsxs)("div",{className:"border-l-4 border-primary pl-4",children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Multi-Agent Evaluation Frameworks"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Developing robust methodologies to evaluate collaboration, specialization, and information sharing between multiple LLM-based agents in complex task environments."})]}),(0,r.jsxs)("div",{className:"border-l-4 border-primary pl-4",children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Context-Aware Reasoning for Ambiguous Tasks"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Building on CondAmbigQA research (EMNLP 2025) to enable LLMs to handle ambiguity through contextual understanding and multi-step reasoning processes."})]}),(0,r.jsxs)("div",{className:"border-l-4 border-emerald-600 pl-4",children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Domain-Specific LLMs for Healthcare"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Extending Pain LLM research to broader healthcare applications, leveraging experience with distributed training on large GPU clusters and behavioral benchmarking."})]}),(0,r.jsxs)("div",{className:"border-l-4 border-primary pl-4",children:[(0,r.jsx)("h3",{className:"font-medium text-lg mb-2",children:"RAG Architecture for Specialized Domains"}),(0,r.jsx)("p",{className:"text-gray-700",children:"Exploring retrieval-augmented generation techniques optimized for domain-specific knowledge integration, focusing on medical and scientific applications."})]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-6",children:"Publications"}),(0,r.jsxs)("div",{className:"space-y-6 mb-10",children:[(0,r.jsxs)("div",{className:"p-5 border rounded-lg border-l-4 border-l-purple-600",children:[(0,r.jsxs)("div",{className:"flex items-center gap-2 mb-2",children:[(0,r.jsx)("span",{className:"tag bg-purple-100 text-purple-800",children:"ACL 2026"}),(0,r.jsx)("span",{className:"text-xs text-gray-500",children:"Under Review"})]}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"BMAM: Brain-inspired Multi-Agent Memory Framework"}),(0,r.jsxs)("p",{className:"text-gray-600 mb-2",children:[(0,r.jsx)("strong",{children:"Y. Li"}),", J. Liu, Y. Wang, Y. Wu, and M. Xu. arXiv:2601.20465"]}),(0,r.jsx)("div",{className:"flex gap-4",children:(0,r.jsx)("a",{href:"https://arxiv.org/abs/2601.20465",target:"_blank",rel:"noopener noreferrer",className:"text-primary hover:underline",children:"arXiv"})})]}),(0,r.jsxs)("div",{className:"p-5 border rounded-lg border-l-4 border-l-blue-600",children:[(0,r.jsxs)("div",{className:"flex items-center gap-2 mb-2",children:[(0,r.jsx)("span",{className:"tag bg-blue-100 text-blue-800",children:"EMNLP 2025"}),(0,r.jsx)("span",{className:"text-xs text-gray-500",children:"Main Conference"})]}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering"}),(0,r.jsxs)("p",{className:"text-gray-600 mb-2",children:["Z. Li*, ",(0,r.jsx)("strong",{children:"Y. Li*"}),", H. Xie, and S. J. Qin. pp. 2269–2288. *Equal contribution"]}),(0,r.jsxs)("div",{className:"flex gap-4",children:[(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Paper"}),(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Code"}),(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Dataset"})]})]}),(0,r.jsxs)("div",{className:"p-5 border rounded-lg border-l-4 border-l-green-600",children:[(0,r.jsx)("div",{className:"flex items-center gap-2 mb-2",children:(0,r.jsx)("span",{className:"tag bg-green-100 text-green-800",children:"KDD 2023"})}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X"}),(0,r.jsxs)("p",{className:"text-gray-600 mb-2",children:["Q. Zheng, X. Xia, X. Zou, ..., ",(0,r.jsx)("strong",{children:"Y. Li"}),", ..., and J. Tang"]}),(0,r.jsxs)("div",{className:"flex gap-4",children:[(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Paper"}),(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Code"})]})]}),(0,r.jsxs)("div",{className:"p-5 border rounded-lg border-l-4 border-l-amber-600",children:[(0,r.jsx)("div",{className:"flex items-center gap-2 mb-2",children:(0,r.jsx)("span",{className:"tag bg-amber-100 text-amber-800",children:"Journal 2023"})}),(0,r.jsx)("h3",{className:"font-medium text-lg",children:"Machine Learning Models for Stroke Detection by Observing Eye-Movement Features Under Five-Color Visual Stimuli in Traditional Chinese Medicine"}),(0,r.jsxs)("p",{className:"text-gray-600 mb-2",children:["Q. Lu, J. Deng, Y. Yu, ",(0,r.jsx)("strong",{children:"Y. Li"}),", et al. Journal of Traditional Chinese Medical Sciences, 10(3), pp. 321–330"]}),(0,r.jsx)("div",{className:"flex gap-4",children:(0,r.jsx)("a",{href:"#",className:"text-primary hover:underline",children:"Paper"})})]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-6",children:"Academic Service"}),(0,r.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4 mb-10",children:[(0,r.jsxs)("div",{className:"p-4 bg-gray-50 rounded-lg",children:[(0,r.jsx)("h3",{className:"font-medium mb-1",children:"Journal Reviewer"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm",children:"Natural Language Processing Journal (2024–2025)"})]}),(0,r.jsxs)("div",{className:"p-4 bg-gray-50 rounded-lg",children:[(0,r.jsx)("h3",{className:"font-medium mb-1",children:"Journal Reviewer"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm",children:"IEEE Internet of Things Journal (2025)"})]}),(0,r.jsxs)("div",{className:"p-4 bg-gray-50 rounded-lg",children:[(0,r.jsx)("h3",{className:"font-medium mb-1",children:"Community Lead"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm",children:"Hugging Face Chinese Community (2022–Present)"})]}),(0,r.jsxs)("div",{className:"p-4 bg-gray-50 rounded-lg",children:[(0,r.jsx)("h3",{className:"font-medium mb-1",children:"Community Volunteer"}),(0,r.jsx)("p",{className:"text-gray-600 text-sm",children:"AITIME (2021–Present)"})]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-6",children:"Contact for PhD Opportunities"}),(0,r.jsxs)("div",{className:"bg-gradient-to-r from-blue-50 to-indigo-50 rounded-lg p-6 border border-blue-100",children:[(0,r.jsx)("p",{className:"mb-4",children:"If you are a professor or research lab looking for PhD students in the field of LLMs, brain-inspired AI, multi-agent systems, or domain-specific models, I would be happy to discuss potential research directions and opportunities."}),(0,r.jsxs)("div",{className:"space-y-2 mb-6",children:[(0,r.jsxs)("p",{children:[(0,r.jsx)("strong",{children:"Email:"})," innovation64feng@gmail.com"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("strong",{children:"Phone:"})," +86 13269183099 / +852 54614337"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("strong",{children:"Current Institution:"})," Guangdong Institute of Intelligence Science and Technology (GIIST)"]})]}),(0,r.jsxs)("div",{className:"flex flex-wrap gap-4",children:[(0,r.jsx)("a",{href:"https://innovation64.github.io/",target:"_blank",rel:"noopener noreferrer",className:"btn btn-primary",children:"View Personal Website"}),(0,r.jsx)("a",{href:"https://scholar.google.com/citations?user=J5CWbnMAAAAJ",target:"_blank",rel:"noopener noreferrer",className:"btn btn-outline",children:"Google Scholar"}),(0,r.jsx)("a",{href:"mailto:innovation64feng@gmail.com",className:"btn bg-gray-200 text-gray-700 hover:bg-gray-300",children:"Email Me"}),(0,r.jsx)(n(),{href:"/research",className:"btn bg-gray-200 text-gray-700 hover:bg-gray-300",children:"View Research"})]})]})]})})})]})}}},function(e){e.O(0,[888,774,179],function(){return e(e.s=2149)}),_N_E=e.O()}]);