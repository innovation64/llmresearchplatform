(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[465],{3878:function(e,s,a){(window.__NEXT_P=window.__NEXT_P||[]).push(["/research",function(){return a(6585)}])},6585:function(e,s,a){"use strict";a.r(s),a.d(s,{default:function(){return t}});var i=a(5893),n=a(1664),r=a.n(n),l=a(6250);function t(){return(0,i.jsxs)("div",{children:[(0,i.jsxs)("section",{className:"relative bg-gradient-to-br from-blue-700 via-blue-800 to-indigo-900 text-white py-20 overflow-hidden",children:[(0,i.jsxs)("div",{className:"absolute inset-0 opacity-10",children:[(0,i.jsx)("div",{className:"absolute top-0 right-0 w-96 h-96 bg-blue-300 rounded-full blur-3xl"}),(0,i.jsx)("div",{className:"absolute bottom-0 left-0 w-72 h-72 bg-indigo-300 rounded-full blur-3xl"})]}),(0,i.jsx)("div",{className:"container mx-auto px-4 relative z-10",children:(0,i.jsxs)("div",{className:"max-w-3xl mx-auto text-center",children:[(0,i.jsx)("h1",{className:"text-4xl md:text-5xl font-bold mb-6",children:"Research Areas"}),(0,i.jsx)("p",{className:"text-xl md:text-2xl mb-4 opacity-90",children:"Exploring the frontiers of large language models and brain-inspired AI"})]})})]}),(0,i.jsx)("section",{className:"section bg-white",children:(0,i.jsx)("div",{className:"container",children:(0,i.jsxs)("div",{className:"max-w-4xl mx-auto",children:[(0,i.jsx)("p",{className:"text-lg text-gray-700 mb-12",children:"My research focuses on advancing large language model capabilities through six interconnected areas: brain-inspired memory architectures, multi-agent systems, retrieval-augmented generation, reasoning mechanisms, domain-specific LLMs, and code generation. The goal is to develop more capable, contextually aware AI systems that can effectively collaborate, retain long-term memory, and reason through complex problems."}),(0,i.jsxs)("div",{className:"space-y-16",children:[(0,i.jsx)("div",{className:"bg-gradient-to-r from-purple-50 to-indigo-50 rounded-lg p-8 border-l-4 border-purple-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-purple-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.yG,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"flex items-center gap-3 mb-4",children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold",children:"Brain-Inspired Memory Architecture"}),(0,i.jsx)("span",{className:"tag bg-purple-100 text-purple-800",children:"Featured"})]}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"This research draws on neuroscience principles to develop memory systems for multi-agent AI frameworks. The BMAM (Brain-inspired Multi-Agent Memory) framework models key brain regions — hippocampus for spatial/episodic memory, prefrontal cortex for reasoning and personality, and temporal lobe for semantic processing — to enable agents with human-like memory consolidation, forgetting, retrieval, and reflection capabilities."}),(0,i.jsxs)("div",{className:"bg-white rounded-lg p-6 mb-6 border",children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-4 text-center text-gray-800",children:"BMAM Architecture Overview"}),(0,i.jsxs)("div",{className:"grid grid-cols-3 gap-4 mb-4",children:[(0,i.jsxs)("div",{className:"bg-purple-50 rounded-lg p-4 text-center border border-purple-200",children:[(0,i.jsx)("div",{className:"text-purple-700 font-semibold mb-1",children:"Hippocampus"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Spatial Memory"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Episodic Encoding"})]}),(0,i.jsxs)("div",{className:"bg-indigo-50 rounded-lg p-4 text-center border border-indigo-200",children:[(0,i.jsx)("div",{className:"text-indigo-700 font-semibold mb-1",children:"Prefrontal Cortex"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Reasoning"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Personality"})]}),(0,i.jsxs)("div",{className:"bg-blue-50 rounded-lg p-4 text-center border border-blue-200",children:[(0,i.jsx)("div",{className:"text-blue-700 font-semibold mb-1",children:"Temporal Lobe"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Semantic Processing"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Long-term Storage"})]})]}),(0,i.jsx)("div",{className:"flex justify-center",children:(0,i.jsxs)("div",{className:"bg-gray-50 rounded-lg px-6 py-3 text-center border border-gray-200",children:[(0,i.jsx)("div",{className:"text-gray-700 font-semibold text-sm",children:"Core Operations"}),(0,i.jsxs)("div",{className:"flex gap-4 mt-1 text-xs text-gray-500",children:[(0,i.jsx)("span",{children:"Consolidation"}),(0,i.jsx)("span",{children:"Forgetting"}),(0,i.jsx)("span",{children:"Retrieval"}),(0,i.jsx)("span",{children:"Reflection"}),(0,i.jsx)("span",{children:"Stress Response"})]})]})})]}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Key Contributions"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"BMAM Framework"})," — Multi-agent memory system with brain region agents (published, arXiv:2601.20465)"]}),(0,i.jsx)("li",{children:"Memory consolidation and distortion modeling"}),(0,i.jsx)("li",{children:"Personality-driven reasoning validation"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Publication"}),(0,i.jsx)("p",{className:"text-gray-600",children:"Y. Li, J. Liu, Y. Wang, Y. Wu, and M. Xu. “BMAM: Brain-inspired Multi-Agent Memory Framework.” arXiv preprint arXiv:2601.20465."})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag bg-purple-100 text-purple-800",children:"BMAM"}),(0,i.jsx)("span",{className:"tag",children:"Neuroscience"}),(0,i.jsx)("span",{className:"tag",children:"Memory Consolidation"}),(0,i.jsx)("span",{className:"tag",children:"Forgetting"}),(0,i.jsx)("span",{className:"tag",children:"Reflection"})]})]})]})}),(0,i.jsx)("div",{className:"bg-gray-50 rounded-lg p-8 border-l-4 border-indigo-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-indigo-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.WY8,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Multi-Agent Systems"}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"This research area focuses on developing frameworks for multiple AI agents to collaborate through specialization and coordination. I investigate both the design of agent architectures and evaluation methodologies to measure effectiveness in complex task environments."}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Current Projects"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"XAgent"})," evaluation framework development (Tsinghua NLP Lab)"]}),(0,i.jsx)("li",{children:"Inter-agent communication protocols"}),(0,i.jsx)("li",{children:"Specialized agent roles and coordination mechanisms"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Key Collaborations"}),(0,i.jsx)("p",{children:"Tsinghua University NLP Lab, GIIST"})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag",children:"XAgent"}),(0,i.jsx)("span",{className:"tag",children:"Agent Collaboration"}),(0,i.jsx)("span",{className:"tag",children:"Evaluation Metrics"}),(0,i.jsx)("span",{className:"tag",children:"Specialization"})]})]})]})}),(0,i.jsx)("div",{className:"bg-gray-50 rounded-lg p-8 border-l-4 border-cyan-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-cyan-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.bGz,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Retrieval-Augmented Generation (RAG)"}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"My work on RAG focuses on enhancing LLMs by retrieving and effectively utilizing external knowledge. The ReproAgent project aims to improve retrieval precision, context integration, and query formulation techniques for more reproducible and robust AI agent research."}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Current Projects"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"ReproAgent"}),": Reproducible agents through enhanced RAG (Tsinghua NLP Lab)"]}),(0,i.jsx)("li",{children:"Context integration techniques for complex queries"}),(0,i.jsx)("li",{children:"Domain-specific retrieval optimization for medical and scientific domains"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Key Collaborations"}),(0,i.jsx)("p",{children:"Tsinghua University NLP Lab, HKMU Research Team"})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag",children:"ReproAgent"}),(0,i.jsx)("span",{className:"tag",children:"Knowledge Integration"}),(0,i.jsx)("span",{className:"tag",children:"Query Optimization"}),(0,i.jsx)("span",{className:"tag",children:"Context Windows"})]})]})]})}),(0,i.jsx)("div",{className:"bg-gray-50 rounded-lg p-8 border-l-4 border-violet-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-violet-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.Par,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"flex items-center gap-3 mb-4",children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold",children:"Reasoning in LLMs"}),(0,i.jsx)("span",{className:"tag bg-blue-100 text-blue-800",children:"EMNLP 2025"})]}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"This research investigates methods to enhance reasoning capabilities in LLMs, particularly for handling ambiguous questions. The CondAmbigQA benchmark (published at EMNLP 2025 Main Conference) demonstrates that condition reasoning improves LLM answer accuracy by up to 18.9%, reframing apparent hallucinations as query ambiguity."}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Key Contributions"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"CondAmbigQA"}),": 2,000-query benchmark with condition-aware evaluation metrics"]}),(0,i.jsx)("li",{children:"Demonstrated 18.9% accuracy improvement via condition reasoning"}),(0,i.jsx)("li",{children:"Contextual disambiguation techniques"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Publication"}),(0,i.jsxs)("p",{className:"text-gray-600",children:["Z. Li*, Y. Li*, H. Xie, and S. J. Qin. “CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering.” ",(0,i.jsx)("strong",{children:"EMNLP 2025"})," (Main Conference), pp. 2269-2288. *Equal contribution"]})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag",children:"CondAmbigQA"}),(0,i.jsx)("span",{className:"tag",children:"Ambiguity Resolution"}),(0,i.jsx)("span",{className:"tag",children:"Chain-of-Thought"}),(0,i.jsx)("span",{className:"tag",children:"Contextual Reasoning"})]})]})]})}),(0,i.jsx)("div",{className:"bg-gradient-to-r from-emerald-50 to-teal-50 rounded-lg p-8 border-l-4 border-emerald-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-emerald-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.bAx,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"flex items-center gap-3 mb-4",children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold",children:"Domain-Specific LLMs"}),(0,i.jsx)("span",{className:"tag bg-emerald-100 text-emerald-800",children:"Current"})]}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"Building specialized large language models for pain analysis and assessment (Pain LLM) at GIIST. This research involves multi-node distributed training on 20+ NVIDIA H100 GPUs, developing pain mouse behavioral benchmarks, and contributing to the China Brain Project."}),(0,i.jsxs)("div",{className:"bg-white rounded-lg p-6 mb-6 border",children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-3 text-gray-800",children:"Training Infrastructure"}),(0,i.jsxs)("div",{className:"grid grid-cols-2 md:grid-cols-4 gap-4 text-center",children:[(0,i.jsxs)("div",{className:"bg-emerald-50 rounded p-3",children:[(0,i.jsx)("div",{className:"text-emerald-700 font-bold text-xl",children:"20+"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"H100 GPUs"})]}),(0,i.jsxs)("div",{className:"bg-emerald-50 rounded p-3",children:[(0,i.jsx)("div",{className:"text-emerald-700 font-bold text-xl",children:"Multi"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Node Training"})]}),(0,i.jsxs)("div",{className:"bg-emerald-50 rounded p-3",children:[(0,i.jsx)("div",{className:"text-emerald-700 font-bold text-xl",children:"Pain"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"LLM Model"})]}),(0,i.jsxs)("div",{className:"bg-emerald-50 rounded p-3",children:[(0,i.jsx)("div",{className:"text-emerald-700 font-bold text-xl",children:"Mouse"}),(0,i.jsx)("div",{className:"text-xs text-gray-500",children:"Benchmark"})]})]})]}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Current Projects"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"Pain LLM"})," — Domain-specific model for pain analysis and assessment"]}),(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"Pain Mouse Benchmark"})," — Behavioral evaluation for pain-related models"]}),(0,i.jsxs)("li",{children:["Contributions to the ",(0,i.jsx)("strong",{children:"China Brain Project"})]}),(0,i.jsx)("li",{children:"FDCT (Macao Science and Technology Development Fund) grant proposals"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Institution"}),(0,i.jsx)("p",{children:"Guangdong Institute of Intelligence Science and Technology (GIIST)"})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag bg-emerald-100 text-emerald-800",children:"Pain LLM"}),(0,i.jsx)("span",{className:"tag",children:"China Brain Project"}),(0,i.jsx)("span",{className:"tag",children:"Distributed Training"}),(0,i.jsx)("span",{className:"tag",children:"H100 GPUs"}),(0,i.jsx)("span",{className:"tag",children:"Behavioral Benchmark"})]})]})]})}),(0,i.jsx)("div",{className:"bg-gray-50 rounded-lg p-8 border-l-4 border-amber-600",children:(0,i.jsxs)("div",{className:"flex items-start",children:[(0,i.jsx)("div",{className:"text-amber-600 mr-4 flex-shrink-0",children:(0,i.jsx)(l.ggF,{size:32})}),(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"flex items-center gap-3 mb-4",children:[(0,i.jsx)("h2",{className:"text-2xl font-semibold",children:"Code Generation"}),(0,i.jsx)("span",{className:"tag bg-green-100 text-green-800",children:"KDD 2023"})]}),(0,i.jsx)("p",{className:"text-gray-700 mb-6",children:"Contributed to CodeGeeX, a pre-trained model for code generation with multilingual benchmarking on HumanEval-X. Developed GLM-based algorithms for poetry generation and content optimization, and improved code-generation models through data analysis and prompt engineering at Zhipu AI (THU KEG)."}),(0,i.jsxs)("div",{className:"space-y-4 mb-6",children:[(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Key Contributions"}),(0,i.jsxs)("ul",{className:"list-disc pl-5 space-y-2",children:[(0,i.jsxs)("li",{children:[(0,i.jsx)("strong",{children:"CodeGeeX"})," — Multilingual code generation model (KDD 2023)"]}),(0,i.jsx)("li",{children:"GLM-based poetry generation and content optimization"}),(0,i.jsx)("li",{children:"Prompt engineering for code generation improvement"})]})]}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-medium text-lg mb-2",children:"Publication"}),(0,i.jsxs)("p",{className:"text-gray-600",children:["Q. Zheng, X. Xia, et al. “CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X.” ",(0,i.jsx)("strong",{children:"KDD 2023"})]})]})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-2",children:[(0,i.jsx)("span",{className:"tag",children:"CodeGeeX"}),(0,i.jsx)("span",{className:"tag",children:"GLM"}),(0,i.jsx)("span",{className:"tag",children:"Zhipu AI"}),(0,i.jsx)("span",{className:"tag",children:"Prompt Engineering"})]})]})]})})]}),(0,i.jsx)("div",{className:"text-center mt-12",children:(0,i.jsx)(r(),{href:"/discuss",className:"btn btn-primary",children:"Discuss Research"})})]})})})]})}}},function(e){e.O(0,[888,774,179],function(){return e(e.s=3878)}),_N_E=e.O()}]);